---
title: "summarizing CAM Data v02"
author: "Noah, Julius"
date: "01 04 2021"
output: 
  html_document:
    toc: yes
    toc_depth: 3
    number_sections: true
bibliography: LibraryAll.bib
biblio-style: apalike
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # define default chunk options


# sets the directory of location of this script as the current directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) 

################
# install and load packages
################
# wenn Pakete nicht bereits installiert sind, wird die Funktion diese installieren und aktivieren
usePackage <- function(p) {
  if (!is.element(p, installed.packages()[,1]))
    install.packages(p, dep = TRUE)
  require(p, character.only = TRUE)
}
## Fehlerbehandlung Pakete in R base installieren
# options(repos="https://CRAN.R-project.org")

usePackage("tidyverse") # data cleaning and summarizing
usePackage("xlsx") # data cleaning and summarizing
usePackage("purr") # data cleaning and summarizing

## text mining / textprocessing
usePackage("SentimentAnalysis")
# usePackage("tm")
# usePackage("qdap")
## output tables
usePackage("stargazer") # Tabellen erstellen
# usePackage("Cairo") # Umgebung, um Grafiken zu speichern
## psychometric analysis
usePackage("psych") 

## meta analysis
usePackage("metafor")
usePackage("meta")

## save pictures
usePackage("Cairo")

################
# load data
################
study2canada <- xlsx::read.xlsx2(file = "data/study2canada_indicatorsCAMs_long.xlsx", sheetIndex = 1)
study2germany <- xlsx::read.xlsx2(file = "data/study2germany_indicatorsCAMs_long.xlsx", sheetIndex = 1)
study3 <- xlsx::read.xlsx2(file = "data/study3_indicatorsCAMs_long.xlsx", sheetIndex = 1)


study2canada <- as.data.frame(sapply(study2canada, as.numeric))
study2germany <- as.data.frame(sapply(study2germany, as.numeric))
study3 <- as.data.frame(sapply(study3, as.numeric))

```

```{r data preperation, include=FALSE}
allthree <- rbind(study2canada, study2germany, study3)

study2canada$group <- "study2canada"
study2germany$group <- "study2germany"
study3$group <- "study3"
three <- rbind(study2canada, study2germany, study3)

three$centralityDummy_CoronaPandemie <- NULL # constant, data entry error
# or
# reflective_column <- function(df, colname = "group") {df[[colname]] <- deparse(substitute(df)); df}
# three <- rbind(reflective_column(study2canada), reflective_column(study2germany), reflective_column(study3))
```

```{r functions, include=FALSE}
## create descreptive tables: 
descreptivefunc <- function(datasets = list(study2canada, study2germany, study3), variable = NULL){
  vec_means <- rep(NA, times = length(datasets)) # c()
  vec_sds <- rep(NA, times = length(datasets))
  for(i in 1:length(datasets)){

    vec_means[i] <- mean(unlist(datasets[[i]][variable]), na.rm = TRUE)
    vec_sds[i] <- sd(unlist(datasets[[i]][variable]), na.rm = TRUE)
  }
  
  combineddataframe <- data.frame(studies = c("study2canada", "study2germany", "study3"),
             mean = vec_means,
             sd = vec_sds)
  
  return(combineddataframe)
}

## save pictures
# ?ggplot2::ggsave()
save_graphic <- function(filename){
  tmp <- paste(filename, ".png", sep = "")
  Cairo::Cairo(file=tmp,
               type="png",
               units="px",
               width=2500,
               height=1700,
               pointsize=44, #text is shrinking by saving graphic
               dpi= "auto",
               bg = "white")
}
```
This is an [R Markdown](http://rmarkdown.rstudio.com) document. Instructions for writing these documents and background information can be found in the book [R Markdown: The Definitive Guide](https://bookdown.org/yihui/rmarkdown/). When you execute code within the document, the results appear beneath the code. 

The aim of this document is to summarize CAM data over different studies. Therefore descreptive and metaanalytical procedures are applied. Fundamental sources for this procedures are [Doing Meta-Analysis in R](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/) and @borenstein2009meta

# Existing CAM data

* 2 COVID-19 Datens채tze
* 1 Datensatz aus 2 Mas (David, Niklas)
* 1 Datensatz aus Ethikseminar
* 1 Datensatz aus Mediationsdesign
* (1 Datensatz Lebens-CAMs) - in Klammern da anderes Konstruktionsprinzip, da angeleitet und von ExpertInnen

# Violations of CAM rules
incompatible connections... @thagard2010empathica



# apply semantic dictionaries
correlation between valence of single nodes and dictionary


# descreptive statististics of network indicators

## number of nodes and edges
```{r nodes1, results='asis'}
descreptivefunc(variable = "num_nodes") %>% 
  stargazer(summary = FALSE, type = "html", digits = 2)
```


```{r nodes2, results='markup'}
descreptivefunc(variable = "num_nodes")
```

```{r nodes3, results='markup'}
three %>%
  group_by(group) %>% 
  summarise(mean(meanDistance_directed))

three %>% 
  group_by(group) %>% 
  summarise(mean(num_nodes))

three %>% 
  group_by(group) %>% 
  summarise(mean(mean_valence), median(mean_valence), sd(mean_valence))

boxplot(three$num_edges_dashed)


# Ideen:
# Percentage of nodes other than 0
# If more node variation then X more often?
# Falls mean von num_nodes gering ausf채llt, fallen dann auch andere nodes geringer aus?
# Hat mean_valence einen Einfluss auf X?
# num_nodes_pos minus num_nodes_neg
# Wenn durchschnittlich mehr nodes auch gleich durchschnittlich mehr num_edges?

three %>%
  group_by(group) %>%
  count(num_nodes_ambi)

# Percentage of nodes other than 0
# teilt noch nicht durch die gez채hlte Anzahl an Zeilen (nrows) sondern durch die manuell gez채hlte


# building a table (wip)

nodes_ambi_bigger0 <- with(three, c(sum(num_nodes_ambi > 0)) / nrow(three))

nodes_neut_bigger0 <- with(three, c(sum(num_nodes_neut > 0)) / nrow(three))
                             
nodes_plot <- data.frame(nodes_ambi_bigger0, nodes_neut_bigger0)

# If more node variation then X more often?

# num_nodes_pos minus num_nodes_neg

three %>% 
  group_by(group) %>% 
  summarise(mean(num_nodes_pos - num_nodes_neg))

# Wenn durchschnittlich mehr nodes auch gleich durchschnittlich mehr num_edges?

with(three, c(sum(num_nodes > num_edges)))
paste0(three$group[with(three, num_nodes > num_edges)], three$CAM_ID[with(three, num_nodes > num_edges)])


with(three, c(sum(num_nodes < num_edges)))
with(three, c(sum(mean(num_nodes) > num_edges)))
with(three, c(sum(mean(num_nodes) < num_edges)))

# Invalid dashed

three$num_edges_invaliddashedpercent <- three$num_edges_invaliddashed / three$num_edges_dashed

three %>%
  group_by(group) %>%
  filter(!is.na(num_edges_invaliddashedpercent)) %>%
  summarise(mean(num_edges_invaliddashedpercent), n())

three %>%
  group_by(group) %>%
  summarise(sum(is.na(num_edges_invaliddashedpercent)))

```


# correlations of network indicators


# topology of CAMs
Blah blah [see @MAkreil2018staircaseelevator, pp. 20ff.]...


# additionally: feedback to CAM software


# additionally: comments to single nodes

# Julius code
```{r randomcode 1, results='markup'}
three %>%
  mutate(baseline = mean(num_nodes), baselineboolean = as.numeric(num_nodes < baseline)) %>%
  group_by(group, baselineboolean) %>%
  summarise(mean(num_nodes_pos))
```

```{r randomcode 2, results='markup'}
psych::cor.plot(r = cor(three[, 2:23], use = "pairwise.complete.obs"), upper = FALSE, xlas = 2)
three$num_edges_invaliddashedpercent <- three$num_edges_invaliddashed / three$num_edges_dashed

# save_graphic(filename = "network indicators all datasets")
# psych::cor.plot(r = cor(three[, 2:23], use = "pairwise.complete.obs"), upper = FALSE, xlas = 2)
# dev.off()
```





# References
